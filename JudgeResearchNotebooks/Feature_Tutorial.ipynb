{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8d98de-01d1-457c-a1ab-248a573c90ff",
   "metadata": {},
   "source": [
    "![werwe](https://uploads-ssl.webflow.com/625391e03972c921373d60ba/6296d332b7e7cd998bf9035b_judge_logo_white.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "\n",
    "# Tutorial:  Towards a Sophisticated Research Methodology \n",
    "\n",
    "*Read time:  11 min.* \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "----\n",
    "\n",
    "This tutorial demonstrates the ease-of-use and power of Judge Research.  If you complete it while referring back to our [wiki](https://judgeresearch.notion.site/The-Judge-Research-Wiki-37d2ae0159254928b483f01fec87b576) whenever a step's logic is not clear to you, you will be fully ready to use Judge Research.  \n",
    "\n",
    "You can use Judge Research to (1) contribute to the decentralized systematic fund & be rewarded; (2) test competing operationalizations with extreme rigour; (3) compare findings from initial (validation set) findings and live findings as they come in; and (4) engineer features that represent something important about the market, and develop rich dashboards that communicate that information in real time.\n",
    "\n",
    "***For a faster tutorial that relies on wrapper functions which turn 30-40 lines of code here into 1 or 2 lines, check out Feature_Tutorial_Short.  Those wrapper functions make it harder to understand what is going on under the hood in the SDK, but make getting down to work a matter of minutes.*** \n",
    "\n",
    "----\n",
    "\n",
    "![](https://uploads-ssl.webflow.com/625391e03972c921373d60ba/626b3edab9b30b7f49b3f554_23519116918_1a87106387_k.jpeg)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b0c0e-f88d-48a9-be6c-87774f704392",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**The Workflow:**  You now have the data environment of a world-class hedge fund at your fingertips.  You can use it in this notebook to engage in feature engineering and display your preliminary findings in a single cohesive document; then submit your features to Judge Research and embed the live, interactive data tools from your dashboard into this document.    \n",
    "\n",
    "**What it Accomplishes:**  With a few clicks, you turn this document into a live research tool linked up to an AI run on massively parallel processes & coded out by a team of PhDs.  It evaluates your features across millions of modeling contexts, ranks and compares them to what is in the market's larger data environment, and rigorously tests them for overfit.    \n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea99b79-d5ea-4b1e-9647-ca68a10d4173",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### The Tech Stack & the Decentralized Systematic Fund\n",
    "\n",
    "This tutorial is meant for those who want to be rewarded for contributing to the decentralized systematic fund, and to use the fund as a new *kind* of research tool.  \n",
    "\n",
    "We will soon be launching a SaaS version of the software.  It will allow you to take advantage of the above functionality without participating in the decentralized fund.  Your features & algorithms will be sent to a version of the AI that only looks at your fund's features and algorithms but still ranks & evaluates them for overfit in real time. \n",
    "\n",
    "Likewise, you can use the SaaS version to collaborate with other funds without revealing IP to one another.  We believe this type of collaboration is novel and has significant implications for the industry - allowing a small set of funds to match the capacities of the largest systematic funds.       \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ba578-4c9b-4629-a922-110eae81e201",
   "metadata": {},
   "source": [
    "# Outline:  The Basic Steps for Submitting Your Features\n",
    "\n",
    "There are **three preliminary steps:**  \n",
    "\n",
    "1.  Authenticate & Setup the Workspace.\n",
    "2.  Configure the parameters of the historical data you would like to call, and the parameters of the series you are studying - for instance, the BTC-USD volatility series at 45 minute intervals.\n",
    "3.  Call the data.\n",
    "\n",
    "Section four is where you will spend 95% of your time:  Here you will **do your data exploration and feature engineering**.  There are then **three final steps:** \n",
    "\n",
    "5.  Submit your historical data.  This historical data submission will cover a time period from the beginning of a specified date - e.g. the 4 hr alpha test series begins on July  2019 - and continue up to the present moment.\n",
    "6.  Schedule the cron job to submit live features.\n",
    "7.  (Optional) Embed the data tools from your dashboard into the same notebook, writing up your findings to create live, interactive research tools and/or market signals. \n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a0143-7cdd-4203-af91-706e715c66b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 1.  Handle Your Authentications & Setup the Workspace\n",
    "Paste your keys and then import the Judge Research & Coinalytix packages, as well as any tools for charting, technical & statistical analysis you might want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98443c8a-890d-4753-82d3-f16e371a0b00",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "JR_API_KEY = 'xxx'\n",
    "CA_API_KEY = 'xxx'\n",
    "\n",
    "\n",
    "from historical_data import Coinalytix, HDParams\n",
    "from judgeresearch import JudgeResearch, JRParams\n",
    "\n",
    "# Import classes for data handling & visualization \n",
    "import json\n",
    "import scipy \n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas_ta as ta\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn\n",
    "import requests # these two not in other imports\n",
    "import json\n",
    "\n",
    "import JudgeHelperFuncs as jh\n",
    "from watchlist import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff0165-be9b-4ed8-b23c-72e2d1e13391",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## 2. Configure Assets, Call, Organize & Clean the Data\n",
    "\n",
    "An easier way to call assets can be found in the Feature_Tutorial_Short.ipynb notebook.  That relies on a few wrapper functions, though, so this tutorial is an easier way to understand what is going on under the hood.  \n",
    "\n",
    "Define the parameters for the historical data you want to call.  Typically, you want to line up the start date(s) of your historical data with the start date of the GA instance(s) to which you'll eventually submit features.  You can finds those dates in our [wiki](https://judgeresearch.notion.site/The-Judge-Research-Wiki-37d2ae0159254928b483f01fec87b576). The below calls data from `startDateString` to t-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2757dae7-8f68-4d71-be74-50bd1931367d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "startDateString = \"2019-09-01 00:00:00\" #     All times are of course in UTC\n",
    "periodsPerDay = 6 #                           MAKE SURE periodsPerDay & intervalString align\n",
    "intervalString = \"4h\" #                       Example arguments:  45m 4h, 1d \n",
    "startDate = datetime.strptime(startDateString, \"%Y-%m-%d %H:%M:%S\")\n",
    "timeBack = datetime.now() - startDate\n",
    "nObs = timeBack.total_seconds() / ((60*60*24) / periodsPerDay) \n",
    "nObs = math.ceil(nObs) #                     number of discrete time blocs up to the present\n",
    "print(nObs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee03174d-f327-40cd-98a9-1a574195c297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The series begins at 2019-09-01 00:00:00.\n",
      "And extends 6395 of obversvations.\n"
     ]
    }
   ],
   "source": [
    "print(\"The series begins at {}.\".format(startDateString)) \n",
    "print(\"And extends {} of obversvations.\".format(nObs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "444fc747-9d96-41ef-aa23-ad2b869bab15",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "asset = HDParams() #                         Set exchange, must be \"BINANCE\" or ...\n",
    "asset.exchange = \"BINANCE\" #                 Set asset, currently supports \"BTC-USD-SPOT\", \"ETH-USD-SPOT\", ...\n",
    "asset.ticker = \"BTC-USDT-SPOT\" #             Set start of reporting period in form YYYY-MM-DD HH:MM:SS\n",
    "asset.set_start_date(startDateString) #      The 4h series for the alpha test start on July 1, 2019. \n",
    "asset.interval = intervalString #            Example arguments:  45m 4h, 1d                     \n",
    "asset.num_periods = nObs #                   Set number of reporting periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc73c9b-9826-4c73-8c22-db728743611e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## 3.a.  Collect Data\n",
    "Authenticate & fetch historical data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8c0b3a7-0787-4250-9c64-91f141fd9fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HD = Coinalytix() #                         Set api key\n",
    "HD.with_api_key(CA_API_KEY) #               Fetch historical data\n",
    "asset_data = HD.fetch_hd(asset) #           Create Pandas data frame from result\n",
    "\n",
    "btc = pd.DataFrame.from_dict(asset_data) #  Adjust DatetimeIndex.\n",
    "btc.set_index(pd.DatetimeIndex(btc[\"StartDate\"]*1000000000), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d6171-56ec-4623-a4d9-146cc7583368",
   "metadata": {},
   "source": [
    "## 3.b. Clean Your Data\n",
    "\n",
    "It is common for exchange data at smaller time blocs to return occasional missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76b795c7-0878-4ece-9315-4654b8ed40f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartDate    0.000000\n",
      "Open         0.000156\n",
      "High         0.000156\n",
      "Low          0.000156\n",
      "Close        0.000156\n",
      "Volume       0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missCount = btc.isna().sum() #      get a sense of how many obs you're missing \n",
    "missPerc = missCount / len(btc)\n",
    "print(missPerc)\n",
    "\n",
    "btc = btc.fillna(method='ffill') #     fill w/ previous observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7ff61-de60-4e69-94e3-a7849492ddf3",
   "metadata": {},
   "source": [
    "Great!  Now that you have set your data environment up, you can carry on to your main job:  Research & Feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada756ab-daba-4614-90ed-f4b5a2107d3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "<img src = \"https://uploads-ssl.webflow.com/625391e03972c921373d60ba/6296d332b7e7cd998bf9035b_judge_logo_white.png\" width=400>\n",
    "\n",
    "## 4.  The Main Section:  Your Feature Engineering Sandbox\n",
    "\n",
    "It is good practice to write your preliminary findings down and frame explicitly the hypotheses you are investigating by sending your features into Judge Research.  Obviously, that is true with all research, but Judge Research is more than an AI:  It suggests an organization to your research that helps you confirm your intitial (validation set) findings with live data *at scale.*\n",
    "\n",
    "That is easy for any professional researcher to do for a small set of findings, but to making research **truly cumulative over the long run** is one of the primary functions of Judge Research. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae67a73d-ede9-492a-8fd9-a27f2b1381dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = (btc['Open'] - btc['Close']) / btc['Open']\n",
    "y1 = y1\n",
    "\n",
    "y1 = pd.concat(([btc['StartDate'], y1]), axis = 1)\n",
    "y1.columns = ['StartDate', 'feature']\n",
    "y1 = y1.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88e2d413-7b6f-4fdc-9ae3-e1a1b64b3435",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StartDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <td>1659312000.0</td>\n",
       "      <td>-0.0024982400714272197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 04:00:00</th>\n",
       "      <td>1659326400.0</td>\n",
       "      <td>0.002019113130224117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 08:00:00</th>\n",
       "      <td>1659340800.0</td>\n",
       "      <td>0.003395745885016303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 12:00:00</th>\n",
       "      <td>1659355200.0</td>\n",
       "      <td>-0.005080119511964112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01 16:00:00</th>\n",
       "      <td>1659369600.0</td>\n",
       "      <td>0.006486546739149043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        StartDate                 feature\n",
       "StartDate                                                \n",
       "2022-08-01 00:00:00  1659312000.0  -0.0024982400714272197\n",
       "2022-08-01 04:00:00  1659326400.0    0.002019113130224117\n",
       "2022-08-01 08:00:00  1659340800.0    0.003395745885016303\n",
       "2022-08-01 12:00:00  1659355200.0   -0.005080119511964112\n",
       "2022-08-01 16:00:00  1659369600.0    0.006486546739149043"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6a798-dbef-4090-b790-1e3a30ed0168",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Research, Chart & Analyze\n",
    "State & chart your preliminary hypotheses and findings here, prior to putting submitting to Judge Research.  One function of these notebooks is to seemlessly organize your live data-derived findings as they come in with your initial findings.  That makes it all the more important to state your initial findings so that you understand what you were thinking weeks or months later.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211a023-f11b-4ae7-83a1-dbcc21fa8716",
   "metadata": {},
   "source": [
    "\n",
    "<img src = \"https://uploads-ssl.webflow.com/625391e03972c921373d60ba/6296d332b7e7cd998bf9035b_judge_logo_white.png\" width=400>\n",
    "\n",
    "## 7.  Reference your live findings\n",
    "\n",
    "Let's do things a bit out of order:  In steps 5 & 6, we submit our historical data & our live data.  \n",
    "\n",
    "We put that at the end of the document, so we can have a cohesive research flow to the research.\n",
    "\n",
    "Add charts from judgeresearch.co -> member portal -> my profile, and paste your iframes in this document.  The below is an example from a team member's profile.\n",
    "\n",
    "Notice the '%%html' that immediately procedes the html object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "267b0ce7-653f-4b9b-9a7d-723cccccd44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://ec2-3-131-96-30.us-east-2.compute.amazonaws.com:3838/ShinyBuild/ScatterPlot/54ckzfe5tj\", width=800, height=500 ></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"http://ec2-3-131-96-30.us-east-2.compute.amazonaws.com:3838/ShinyBuild/ScatterPlot/54ckzfe5tj\", width=800, height=500 ></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30a1fdef-5cb1-4f39-bba2-31e5ee9719f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://ec2-3-131-96-30.us-east-2.compute.amazonaws.com:3838/ShinyBuild/LinePlot/54ckzfe5tj\", width=800, height=500 ></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"http://ec2-3-131-96-30.us-east-2.compute.amazonaws.com:3838/ShinyBuild/LinePlot/54ckzfe5tj\", width=800, height=500 ></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba79ee-42bd-4de5-b231-533015da4b83",
   "metadata": {},
   "source": [
    "To submit historical data to Judge Research's AI, you,\n",
    "\n",
    "1.  Prepare the connection, \n",
    "\n",
    "2.  Choose information to tell the API: \n",
    "- The instance of the GA you are submitting (e.g. BTC-USD at a 4 hour time period) \n",
    "- What you are labeling your feature (e.g. 'x1' so as to not reveal any IP), and \n",
    "- The interpolation procedure for when you miss the occassional submission.\n",
    "\n",
    "3.  Fromat the payload\n",
    "4.  And submit the feature!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32c752b5-7fbb-432b-afb7-24137942b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "JR = JudgeResearch()\n",
    "JR.with_api_key(JR_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a85c8fb-efc0-4999-9d8f-ddafa6b5d429",
   "metadata": {},
   "source": [
    "Format the Historical Features:  Below we specify which instance(s) of the AI are going to receive our feature(s).  Each instance is trained on a different dependent variable.   We communicate this to Judge Research by formatting our feature(s) as their JSON.  See the [API documentation in our wiki](https://judgeresearch.notion.site/Use-The-API-5143af17c10f407d91a8860a7c91936e) for information about each argument. \n",
    "\n",
    "For example, here we specify this submission is for BTC-USD at the 45 minute interval, and we label it 'BTCt' for BTC at time *t*.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5f60c-299d-4947-8c9d-02a2a680fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_params = JRParams()\n",
    "ft_params.mbs= '240'  #               mbs: 'minute bloc size' - the size of the discrete time bloc.  In the alpha test, options are 45 & 240.  \n",
    "ft_params.feature_name = \"ETHt\" #     feature_name: name it to represent the substance of the feature or generically so no one but you knows what it is; e.g. 'x1'\n",
    "ft_params.dv = 'ETH-USD' #            the dependent variable you are attempting to help explain\n",
    "ft_params.ipp = \"last\" #              ipp: interpolation procedure - fill-in value if you miss a submission.  'last' or 'zero'\n",
    "\n",
    "features = JR.craft_features(ft_params, y1)\n",
    "payload = JR.format_payload(features)\n",
    "submit = JR.submit_feature(payload)\n",
    "print(submit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d17797-2475-4e55-bca8-eb050683e37c",
   "metadata": {},
   "source": [
    "You can submit the same feature to multiple series of the GA.  Check out Feature_Tutorial_Short.ipynb for an example.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e2eb9-ad26-4fe5-a4d0-6f044586d802",
   "metadata": {},
   "source": [
    "## 6. Live Feature Calculation and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f77bb-d8f0-4256-a34b-94640cf6bf4c",
   "metadata": {},
   "source": [
    "Now it's time to schedule the live submissions.  You don't want to load a full notebook every time, so switch over to Feature_Tutorial_live.py to see the rest of the introductory tutorial.  You can find the functions that script calls in the JudgeHelperFuncs.py module, which we typically load into workspaces as 'jh'.  \n",
    "\n",
    "There are a few idiosyncrasies that come from scheduling the cron job w/ Docker's build.  It just requires you to tweak the cron a bit.  So we put together a short [page of our wiki](https://judgeresearch.notion.site/Scheduling-Your-Live-Send-Scripts-fc64827cedf4469ab826e1df2c25867f) for your convenience.  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
