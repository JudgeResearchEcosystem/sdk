{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8d98de-01d1-457c-a1ab-248a573c90ff",
   "metadata": {},
   "source": [
    "![werwe](https://uploads-ssl.webflow.com/625391e03972c921373d60ba/6296d332b7e7cd998bf9035b_judge_logo_white.png)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "\n",
    "# Tutorial:  Towards a Sophisticated Research Methodology \n",
    "\n",
    "*Read time:  11 min.* \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "----\n",
    "\n",
    "This tutorial demonstrates the ease-of-use and power of Judge Research.  If you complete it while referring back to our [wiki](https://judgeresearch.notion.site/The-Judge-Research-Wiki-37d2ae0159254928b483f01fec87b576) whenever a step's logic is not clear to you, you will be fully ready to use Judge Research.  \n",
    "\n",
    "You can use Judge Research to (1) contribute to the decentralized systematic fund & be rewarded; (2) test competing operationalizations with extreme rigour; (3) compare findings from initial (validation set) findings and live findings as they come in; and (4) engineer features that represent something important about the market, and develop rich dashboards that communicate that information in real time.\n",
    "\n",
    "----\n",
    "\n",
    "![](https://uploads-ssl.webflow.com/625391e03972c921373d60ba/626b3edab9b30b7f49b3f554_23519116918_1a87106387_k.jpeg)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b0c0e-f88d-48a9-be6c-87774f704392",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**The Workflow:**  You now have the data environment of a world-class hedge fund at your fingertips.  You can use it in this notebook to engage in feature engineering and display your preliminary findings in a single cohesive document; then submit your features to Judge Research and embed the live, interactive data tools from your dashboard into this document.    \n",
    "\n",
    "**What it Accomplishes:**  With a few clicks, you turn this document into a live research tool linked up to an AI run on massively parallel processes & coded out by a team of PhDs.  It evaluates your features across millions of modeling contexts, ranks and compares them to what is in the market's larger data environment, and rigorously tests them for overfit.    \n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea99b79-d5ea-4b1e-9647-ca68a10d4173",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### The Tech Stack & the Decentralized Systematic Fund\n",
    "\n",
    "This tutorial is meant for those who want to be rewarded for contributing to the decentralized systematic fund, and to use the fund as a new *kind* of research tool.  \n",
    "\n",
    "We will soon be launching a SaaS version of the software.  It will allow you to take advantage of the above functionality without participating in the decentralized fund.  Your features & algorithms will be sent to a version of the AI that only looks at your fund's features and algorithms but still ranks & evaluates them for overfit in real time. \n",
    "\n",
    "Likewise, you can use the SaaS version to collaborate with other funds without revealing IP to one another.  We believe this type of collaboration is novel and has significant implications for the industry - allowing a small set of funds to match the capacities of the largest systematic funds.       \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ba578-4c9b-4629-a922-110eae81e201",
   "metadata": {},
   "source": [
    "# Outline:  The Basic Steps for Submitting Your Features\n",
    "\n",
    "There are **three preliminary steps:**  \n",
    "\n",
    "1.  Authenticate & Setup the Workspace.\n",
    "2.  Configure the parameters of the historical data you would like to call, and the parameters of the series you are studying - for instance, the BTC-USD volatility series at 45 minute intervals.\n",
    "3.  Call, Organize & Clean the data.  \n",
    "\n",
    "These three steps are broken out by their underlying functions in the longer tutorial.  Here, wrapper functions shorten about 30 lines of code to one.  \n",
    "\n",
    "Step four is where you will spend 95% of your time:  Here you will **do your data exploration and feature engineering**.  There are then **three final steps:** \n",
    "\n",
    "5.  Submit your historical data.  This historical data submission will cover a time period from the beginning of a specified date - e.g. the 4 hr alpha test series begins on July  2019 - and continue up to the present moment.\n",
    "6.  Schedule the cron job to submit live features.\n",
    "7.  (Optional) Embed the data tools from your dashboard into the same notebook, writing up your findings to create live, interactive research tools and/or market signals. \n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a0143-7cdd-4203-af91-706e715c66b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 1.  Handle Your Authentications & Setup the Workspace\n",
    "\n",
    "You can run this code for-real by hitting shift + enter in each codeblock.  But first go and get your API keys  from [Coinalytix](www.coinalytix.io) and [Judge Research](www.judgeresearch.co)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac88d1d-ba1b-494d-a814-2d1c3d5cd55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JR_API_KEY = \"xxx\" # Your Judge Research API was given to you upon sign-up.  You can find it under your profile.\n",
    "CA_API_KEY = \"xxx\" # Sign up at Coinalytix.io - 90 days free and no payment information need be entered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34101f15-e2ea-451d-92f0-29d228d05169",
   "metadata": {},
   "source": [
    "Import the Judge Research & Coinalytix packages, as well as the python tools want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98443c8a-890d-4753-82d3-f16e371a0b00",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import classes that handle API connections and parameters\n",
    "from historical_data import Coinalytix, HDParams\n",
    "from judgeresearch import JudgeResearch, JRParams\n",
    "\n",
    "# Import classes for data handling & visualization \n",
    "import json\n",
    "import scipy \n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas_ta as ta\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn\n",
    "import requests # these two not in other imports\n",
    "import json\n",
    "\n",
    "import JudgeHelperFuncs as jh\n",
    "from watchlist import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff0165-be9b-4ed8-b23c-72e2d1e13391",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "## 2. Configure Assets, Call, Organize & Clean the Data\n",
    "Define the parameters for the historical data you want to call.  Typically, you want to line up the start date(s) of your historical data with the start date of the GA instance(s) to which you'll eventually submit features.  You can finds those dates in our [wiki](https://judgeresearch.notion.site/The-Judge-Research-Wiki-37d2ae0159254928b483f01fec87b576). The below calls data from `startDateString` to t-1. \n",
    "\n",
    "One useful convenience function from the JudgeHelperFuncs module is a little regex + querying coinalytix for what assets are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "411941a7-881f-4cba-b41f-e624df31ea60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Exchange           Ticker\n",
      "67   BINANCE   ETH-USD-200925\n",
      "68   BINANCE   ETH-USD-201225\n",
      "69   BINANCE   ETH-USD-210326\n",
      "70   BINANCE   ETH-USD-210625\n",
      "71   BINANCE   ETH-USD-210924\n",
      "72   BINANCE   ETH-USD-211231\n",
      "73   BINANCE   ETH-USD-220325\n",
      "74   BINANCE   ETH-USD-220624\n",
      "75   BINANCE   ETH-USD-220930\n",
      "76   BINANCE     ETH-USD-PERP\n",
      "156      FTX  ETH-USDT-220624\n",
      "157      FTX  ETH-USDT-220930\n",
      "158      FTX  ETH-USDT-221230\n",
      "159      FTX    ETH-USDT-PERP\n",
      "231   KRAKEN   ETH-USD-190329\n",
      "232   KRAKEN   ETH-USD-190628\n",
      "233   KRAKEN   ETH-USD-190927\n",
      "234   KRAKEN   ETH-USD-191227\n",
      "235   KRAKEN   ETH-USD-200327\n",
      "236   KRAKEN   ETH-USD-200626\n",
      "237   KRAKEN   ETH-USD-200925\n",
      "238   KRAKEN   ETH-USD-201225\n",
      "239   KRAKEN   ETH-USD-210326\n",
      "240   KRAKEN   ETH-USD-210625\n",
      "241   KRAKEN   ETH-USD-210924\n",
      "242   KRAKEN   ETH-USD-211231\n",
      "243   KRAKEN   ETH-USD-220325\n",
      "244   KRAKEN   ETH-USD-220624\n",
      "245   KRAKEN   ETH-USD-220729\n",
      "246   KRAKEN   ETH-USD-220826\n",
      "247   KRAKEN   ETH-USD-220930\n",
      "248   KRAKEN   ETH-USD-221230\n",
      "249   KRAKEN     ETH-USD-PERP\n"
     ]
    }
   ],
   "source": [
    "tc = jh.whichTickers(verbose = False, apiKey = CA_API_KEY, Which2 = \"ETH\", Which='[0-9]+|PERP', WhichExch ='') # tc: this call\n",
    "print(tc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12393a3c-b1f1-41a1-a324-2710cd20d91d",
   "metadata": {},
   "source": [
    "Instead of pulling assets from this DataFrame, let's start with an easy call of a couple spot prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c896351-9d97-4ce4-beb7-557a86fb5ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbs = '45m'                            # time block size:  1h, 4h, 1d, etc.\n",
    "MBS = '45' #                           # minute bloc size:  for submitting to JR's API.  accord with \n",
    "thisDateStart = \"2022-01-01 00:00:00\"  # always as a string denoted as so\n",
    "\n",
    "XDict = jh.assetCallLoop(exchangeList = ['BINANCE', 'BINANCE', 'BINANCE'], assetList = ['ETH-USDT-SPOT', 'BTC-USDT-SPOT', 'SOL-USDT-SPOT'], startDateString = thisDateStart, perSize = tbs, APIKey = CA_API_KEY, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada756ab-daba-4614-90ed-f4b5a2107d3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "<img src = \"https://uploads-ssl.webflow.com/625391e03972c921373d60ba/6296d332b7e7cd998bf9035b_judge_logo_white.png\" width=400>\n",
    "\n",
    "## 4.  The Main Section:  Your Feature Engineering Sandbox\n",
    "\n",
    "Judge Research suggests an organization to your research that helps you confirm your intitial (validation set) findings with live data *at scale.*\n",
    "\n",
    "That is easy for any professional researcher to do for a small set of findings, but to making research **truly cumulative over the long run** is one of the primary functions of our AI, and your ability to plug its findings into these notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd850b31-afce-41f4-b786-5478887c0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make our working example super simple for sake of focusing on the workflow:\n",
    "\n",
    "eth = XDict['ETH-USDT-SPOT']\n",
    "btc = XDict['BTC-USDT-SPOT']\n",
    "sol = XDict['SOL-USDT-SPOT']\n",
    "\n",
    "def percDif(y):\n",
    "    x = (y['Open'] - y['Close']) / y['Open']\n",
    "    z = pd.concat(([y['StartDate'], x]), axis = 1)\n",
    "    z.columns = ['StartDate', 'feature']\n",
    "    z = z.applymap(str)\n",
    "    return(z)\n",
    "\n",
    "\n",
    "y1 = percDif(eth)\n",
    "y2 = percDif(btc)\n",
    "y3 = percDif(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e190b2-5bfe-4b26-8473-a7bf665e0d13",
   "metadata": {},
   "source": [
    "Notice the three formatting lines at the end of the function.  That's the only overhead you'll need to make your features play well with the SDK's formatting & submission scripts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4981dba-f07f-4490-99f2-b2afff69f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21220620-71ab-4ed7-b74f-e169f81a6665",
   "metadata": {},
   "source": [
    "### A Slightly Busier Example \n",
    "\n",
    "Here are some simple moving average-related functions housed in one function.  You can ignore the details.  The key substantive point is our AI is really useful for comparing operationalizations of related concepts.  Normally when one compares opationalizations it is in a single research context, and that (n = 1) workflow leads to overfitting or fragile research. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8e13f-2327-4f51-939c-5c92faa29d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_gen(df):\n",
    "    ''' calculate macd, awesome oscillator, and bbands '''\n",
    "    df.ta.macd(fast=8, slow=21, signal=9, min_periods=None, append=True) #                      MACD\n",
    "    df.ta.ao(high=df[\"High\"], low=df[\"Low\"], window1=5, window2=34, fillna=True, append=True) # Awesome Oscillator \n",
    "    df[\"AO_5_34\"] = pd.to_numeric(df[\"AO_5_34\"])\n",
    "    df.ta.bbands(close=df[\"Close\"], append=True) #                                              Bollinger Bands\n",
    "    df[\"feature\"] = (df[\"AO_5_34\"] - df[\"MACDs_8_21_9\"]) * df[\"BBP_5_2.0\"] #                    Calculate the feature by finding the difference of MACDs and AO, multiply by BBANDS\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "otherExample = feature_gen(eth)\n",
    "\n",
    "otherExample.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f615dbe-6b37-41fc-bb7d-69356761f804",
   "metadata": {},
   "source": [
    "The key data-wrangling point below is to notice how the final feature that one wants to submit is labeled, exactly, 'feature.'  The SDK's formatting function takes in a time series DataFrame, grabs the column labeled 'feature', and the row labels, and translates it into a JSON that Judge Research's API understands.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8859cee3-703e-4daa-a7aa-ff410b7f517a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Write Up Your Findings\n",
    "\n",
    "Spend extra time writing up your initial findings so the live findings speak to those initial thoughts months or even years later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e025d06-6fa3-48ab-9676-2c9ffc88720f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac4ffd-39b3-4299-988c-67fb68a86888",
   "metadata": {},
   "source": [
    "\n",
    "<img src = \"https://uploads-ssl.webflow.com/625391e03972c921373d60ba/6296d332b7e7cd998bf9035b_judge_logo_white.png\" width=400>\n",
    "\n",
    "## 7.  Reference your live findings\n",
    "\n",
    "Let's do things a bit out of order:  In steps 5 & 6, we submit our historical data & our live data.  \n",
    "\n",
    "We put that at the end of the document, so we can have a cohesive research flow to the research.\n",
    "\n",
    "Add charts from judgeresearch.co -> member portal -> my profile, and paste your iframes in this document.  The below is an example from a team member's profile.\n",
    "\n",
    "Notice the '%%html' that immediately procedes the html object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c112c89-61cb-4813-b033-54c9c0ec97f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://ec2-3-131-96-30.us-east-2.compute.amazonaws.com:3838/ShinyBuild/ScatterPlot/54ckzfe5tj\", width=800, height=500 ></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"http://ec2-3-131-96-30.us-east-2.compute.amazonaws.com:3838/ShinyBuild/ScatterPlot/54ckzfe5tj\", width=800, height=500 ></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b66cb1c-ab83-4288-810b-1ab14cd95bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://ec2-3-131-96-30.us-east-2.compute.amazonaws.com:3838/ShinyBuild/LinePlot/54ckzfe5tj\", width=800, height=500 ></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"http://ec2-3-131-96-30.us-east-2.compute.amazonaws.com:3838/ShinyBuild/LinePlot/54ckzfe5tj\", width=800, height=500 ></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6e3d7-6492-40e7-8e09-35451cb78e2f",
   "metadata": {},
   "source": [
    "----\n",
    "## Steps 5 Submitting Your Feature's Historial Time Series to Judge Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f6371-1311-463a-a469-3c6b665674e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To submit historical data to Judge Research's AI, you,\n",
    "\n",
    "1.  Prepare the connection, \n",
    "\n",
    "2.  Choose information to tell the API: \n",
    "- The instance of the GA you are submitting (e.g. BTC-USD at a 4 hour time period) \n",
    "- What you are labeling your feature (e.g. 'x1' so as to not reveal any IP), and \n",
    "- The interpolation procedure for when you miss the occassional submission.\n",
    "\n",
    "3.  Fromat the payload\n",
    "4.  And submit the feature!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10588eb-a470-4763-a187-e850010b00f1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "JR = JudgeResearch()\n",
    "JR.with_api_key(JR_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c3647d-07db-4375-a28c-d644a889b236",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Format the Historical Features:  Below we specify which instance(s) of the AI are going to receive our feature(s).  Each instance is trained on a different dependent variable.   We communicate this to Judge Research by formatting our feature(s) as their JSON.  See the [API documentation in our wiki](https://judgeresearch.notion.site/Use-The-API-5143af17c10f407d91a8860a7c91936e) for information about each argument. \n",
    "\n",
    "For example, here we specify this submission is for BTC-USD at the 45 minute interval, and we label it 'BTCt' for BTC at time *t*.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b5fefa-76e6-4498-92c9-18cc4a293731",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ft_params = JRParams()\n",
    "ft_params.mbs= MBS  #                 mbs: 'minute bloc size' - the size of the discrete time bloc.  In the alpha test, options are 45 & 240.  \n",
    "ft_params.feature_name = \"ETHt\" #     feature_name: name it to represent the substance of the feature or generically so no one but you knows what it is; e.g. 'x1'\n",
    "ft_params.dv = 'ETH-USD' #            the dependent variable you are attempting to help explain\n",
    "ft_params.ipp = \"last\" #              ipp: interpolation procedure - fill-in value if you miss a submission.  'last' or 'zero'\n",
    "\n",
    "features = JR.craft_features(ft_params, y1)\n",
    "payload = JR.format_payload(features)\n",
    "submit = JR.submit_feature(payload)\n",
    "#print(submit)\n",
    "#print(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6ff58-4834-4d7a-beb7-b8ddfa715546",
   "metadata": {},
   "source": [
    "You can submit the same feature to multiple series of the GA.  Here we use the same code as above to submit three features each to each of the alpha test series that make one step ahead forecasts at the four hour interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e539f6-55db-4fd5-9cb3-c234f6135970",
   "metadata": {},
   "outputs": [],
   "source": [
    "myVarNames = ('ETHt', 'BTCt', 'SOLt') #                    i as counter\n",
    "myDVs = ('ETH-USD', 'V-ETH-USD', 'BTC-USD', 'V-BTC-USD') # j as counter\n",
    "\n",
    "for j in range(len(myDVs)):\n",
    "    i = 0\n",
    "    for k, v in XDict.items():\n",
    "        y1 = percDif(v)\n",
    "        JR = JudgeResearch()\n",
    "        JR.with_api_key(JR_API_KEY)\n",
    "        ft_params = JRParams()\n",
    "        # MR got rid of MBS 240 below wasn't working\n",
    "        ft_params.mbs= MBS    \n",
    "        ft_params.feature_name = myVarNames[i]\n",
    "        ft_params.dv = myDVs[j]\n",
    "        ft_params.ipp = \"last\"\n",
    "        features = JR.craft_features(ft_params, y1)\n",
    "        payload = JR.format_payload(features)\n",
    "        submit = JR.submit_feature(payload)\n",
    "        print(submit)\n",
    "        i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054eb82e-7bf8-433d-9bd8-cc0956b8826b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ac043-3682-4c68-882e-5b25eb03bee3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## 6. Live Feature Calculation and Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780d9e8-b224-432b-897e-93f5f0a3ebc9",
   "metadata": {},
   "source": [
    "Now it's time to schedule the live submissions.  You don't want to load a full notebook every time, so switch over to Feature_Tutorial_live.py to see the rest of the introductory tutorial.  You can find the functions that script calls in the JudgeHelperFuncs.py module, which we typically load into workspaces as 'jh'.  \n",
    "\n",
    "There are a few idiosyncrasies that come from scheduling the cron job w/ Docker's build.  It just requires you to tweak the cron a bit.  So we put together a short [page of our wiki](https://judgeresearch.notion.site/Scheduling-Your-Live-Send-Scripts-fc64827cedf4469ab826e1df2c25867f) for your convenience.  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
